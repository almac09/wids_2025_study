{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49cbd957",
   "metadata": {},
   "source": [
    "[link to original notebook](https://www.kaggle.com/code/olaflundstrom/wids-datathon-2025-adhd-analysis-notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdde0d",
   "metadata": {
    "papermill": {
     "duration": 0.00286,
     "end_time": "2025-01-24T17:43:02.516390",
     "exception": false,
     "start_time": "2025-01-24T17:43:02.513530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# WiDS Datathon 2025: Predicting ADHD and Sex from fMRI Data\n",
    "\n",
    "This notebook provides a step-by-step guide to solving the WiDS Datathon 2025 challenge. The goal is to predict both an individual's sex and their ADHD diagnosis using functional brain imaging data, socio-demographic information, and other metadata.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Data Loading](#data-loading)\n",
    "3. [Data Preprocessing](#data-preprocessing)\n",
    "4. [Model Training](#model-training)\n",
    "5. [Model Evaluation](#model-evaluation)\n",
    "6. [Submission Generation](#submission-generation)\n",
    "7. [Conclusion](#conclusion)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "The WiDS Datathon 2025 focuses on uncovering patterns in ADHD diagnosis and sex differences using fMRI data. The dataset includes:\n",
    "- Functional MRI connectome matrices\n",
    "- Socio-demographic information\n",
    "- Emotional and parenting questionnaire data\n",
    "\n",
    "Our task is to build a multi-output model to predict:\n",
    "1. ADHD diagnosis (`ADHD_Outcome`: 1 = yes, 0 = no)\n",
    "2. Sex (`Sex_F`: 1 = female, 0 = male)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Loading <a name=\"data-loading\"></a>\n",
    "\n",
    "We start by loading the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee587fe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:43:02.522180Z",
     "iopub.status.busy": "2025-01-24T17:43:02.521875Z",
     "iopub.status.idle": "2025-01-24T17:43:23.449910Z",
     "shell.execute_reply": "2025-01-24T17:43:23.449042Z"
    },
    "papermill": {
     "duration": 20.932657,
     "end_time": "2025-01-24T17:43:23.451565",
     "exception": false,
     "start_time": "2025-01-24T17:43:02.518908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alan.mcdonagh\\OneDrive - Milliman Inc\\Projects\\51. WiDS Datathon 2025\\input\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m fpath_input \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m..\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(fpath_input)\n\u001b[1;32m----> 7\u001b[0m \u001b[43ms\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_feats\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAIN\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    Load data for the specified mode (TRAIN or TEST).\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "fpath_input = os.path.abspath('..\\\\..\\\\..\\\\..\\\\input')\n",
    "print(fpath_input)\n",
    "s\n",
    "\n",
    "\n",
    "def get_feats(mode='TRAIN'):\n",
    "    \"\"\"\n",
    "    Load data for the specified mode (TRAIN or TEST).\n",
    "    \"\"\"\n",
    "    # Load quantitative metadata\n",
    "    feats = pd.read_excel(f\"{fpath_input}/widsdatathon2025/{mode}/{mode}_QUANTITATIVE_METADATA.xlsx\")\n",
    "    \n",
    "    # Load categorical metadata\n",
    "    if mode == 'TRAIN':\n",
    "        cate = pd.read_excel(f\"{fpath_input}/widsdatathon2025/{mode}/{mode}_CATEGORICAL_METADATA.xlsx\")\n",
    "    else:\n",
    "        cate = pd.read_excel(f\"{fpath_input}/widsdatathon2025/{mode}/{mode}_CATEGORICAL.xlsx\")\n",
    "    \n",
    "    # Merge quantitative and categorical data\n",
    "    feats = pd.merge(feats, cate, on='participant_id', how='left')\n",
    "    \n",
    "    # Load functional connectome matrices\n",
    "    func = pd.read_csv(f\"{fpath_input}/widsdatathon2025/{mode}/{mode}_FUNCTIONAL_CONNECTOME_MATRICES.csv\")\n",
    "    feats = pd.merge(feats, func, on='participant_id', how='left')\n",
    "    \n",
    "    # Load training solutions (only for TRAIN mode)\n",
    "    if mode == 'TRAIN':\n",
    "        solution = pd.read_excel(f\"{fpath_input}/widsdatathon2025/TRAIN/TRAINING_SOLUTIONS.xlsx\")\n",
    "        feats = pd.merge(feats, solution, on='participant_id', how='left')\n",
    "    \n",
    "    return feats\n",
    "\n",
    "# Load training and test data\n",
    "print(\"Loading data...\")\n",
    "train = get_feats(mode='TRAIN')\n",
    "test = get_feats(mode='TEST')\n",
    "\n",
    "# Display the first few rows of the training data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff5172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8198a4ae9dbf4678a7aa2b4d2fb0b8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'VisibleDeprecationWarning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msweetviz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msv\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Generate a Sweetviz report comparing train and test datasets\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43msv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairwise_analysis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alan.mcdonagh\\anaconda3\\envs\\milliman_dublin_v005\\lib\\site-packages\\sweetviz\\sv_public.py:22\u001b[0m, in \u001b[0;36mcompare\u001b[1;34m(source, compare, target_feat, feat_cfg, pairwise_analysis)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompare\u001b[39m(source: Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, Tuple[pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m     18\u001b[0m             compare: Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, Tuple[pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m     19\u001b[0m             target_feat: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     20\u001b[0m             feat_cfg: FeatureConfig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     21\u001b[0m             pairwise_analysis: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 22\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43msweetviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataframeReport\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompare\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mpairwise_analysis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m report\n",
      "File \u001b[1;32mc:\\Users\\alan.mcdonagh\\anaconda3\\envs\\milliman_dublin_v005\\lib\\site-packages\\sweetviz\\dataframe_report.py:277\u001b[0m, in \u001b[0;36mDataframeReport.__init__\u001b[1;34m(self, source, target_feature_name, compare, pairwise_analysis, fc, verbosity)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features_to_process:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# start = time.perf_counter()\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mset_description_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features[f\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43msa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_feature_to_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# print(f\"DONE FEATURE------> {f.source.name}\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m#       f\" {(time.perf_counter() - start):.2f}   {self._features[f.source.name]['type']}\")\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# self.progress_bar.set_description_str('[FEATURES DONE]')\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# self.progress_bar.close()\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Wrap up summary\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alan.mcdonagh\\anaconda3\\envs\\milliman_dublin_v005\\lib\\site-packages\\sweetviz\\series_analyzer.py:142\u001b[0m, in \u001b[0;36manalyze_feature_to_dictionary\u001b[1;34m(to_process)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Perform full analysis on source/compare/target\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m returned_feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m FeatureType\u001b[38;5;241m.\u001b[39mTYPE_NUM:\n\u001b[1;32m--> 142\u001b[0m     \u001b[43msweetviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries_analyzer_numeric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturned_feature_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m returned_feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m FeatureType\u001b[38;5;241m.\u001b[39mTYPE_CAT:\n\u001b[0;32m    144\u001b[0m     sweetviz\u001b[38;5;241m.\u001b[39mseries_analyzer_cat\u001b[38;5;241m.\u001b[39manalyze(to_process, returned_feature_dict)\n",
      "File \u001b[1;32mc:\\Users\\alan.mcdonagh\\anaconda3\\envs\\milliman_dublin_v005\\lib\\site-packages\\sweetviz\\series_analyzer_numeric.py:102\u001b[0m, in \u001b[0;36manalyze\u001b[1;34m(to_process, feature_dict)\u001b[0m\n\u001b[0;32m     98\u001b[0m     do_stats_numeric(to_process\u001b[38;5;241m.\u001b[39mcompare, compare_dict)\n\u001b[0;32m    100\u001b[0m do_detail_numeric(to_process\u001b[38;5;241m.\u001b[39msource, to_process\u001b[38;5;241m.\u001b[39msource_counts, to_process\u001b[38;5;241m.\u001b[39mcompare_counts, feature_dict)\n\u001b[1;32m--> 102\u001b[0m feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminigraph\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mGraphNumeric\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_process\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail_graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_bins \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m30\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\alan.mcdonagh\\anaconda3\\envs\\milliman_dublin_v005\\lib\\site-packages\\sweetviz\\graph_numeric.py:71\u001b[0m, in \u001b[0;36mGraphNumeric.__init__\u001b[1;34m(self, which_graph, to_process)\u001b[0m\n\u001b[0;32m     67\u001b[0m     normalizing_weights \u001b[38;5;241m=\u001b[39m norm_source\n\u001b[0;32m     69\u001b[0m gap_percent \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mgetfloat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_graph_categorical_gap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVisibleDeprecationWarning\u001b[49m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist_specs \u001b[38;5;241m=\u001b[39m axs\u001b[38;5;241m.\u001b[39mhist(plot_data, weights \u001b[38;5;241m=\u001b[39m normalizing_weights, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, \\\n\u001b[0;32m     73\u001b[0m                            rwidth \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m-\u001b[39m gap_percent) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100.0\u001b[39m)\n\u001b[0;32m     74\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monce\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning)\n",
      "File \u001b[1;32mc:\\Users\\alan.mcdonagh\\anaconda3\\envs\\milliman_dublin_v005\\lib\\site-packages\\numpy\\__init__.py:410\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[1;32m--> 410\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'VisibleDeprecationWarning'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "# Generate a Sweetviz report comparing train and test datasets\n",
    "# Generate a Sweetviz report comparing train and test datasets\n",
    "report = sv.compare(\n",
    "    [train, \"Train\"], \n",
    "    [test, \"Test\"],\n",
    "    pairwise_analysis='on',\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b10ce52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Pairwise analysis is turned off to avoid detailed pairwise feature comparisons\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# This can speed up the report generation and reduce the report size\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43msv\u001b[49m\u001b[38;5;241m.\u001b[39mcompare(\n\u001b[0;32m      4\u001b[0m     [train, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m], \n\u001b[0;32m      5\u001b[0m     [test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      6\u001b[0m     pairwise_analysis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m report\u001b[38;5;241m.\u001b[39mshow_html(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msweetviz_compare.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sv' is not defined"
     ]
    }
   ],
   "source": [
    "# Pairwise analysis is turned off to avoid detailed pairwise feature comparisons\n",
    "# This can speed up the report generation and reduce the report size\n",
    "report = sv.compare(\n",
    "    [train, \"Train\"], \n",
    "    [test, \"Test\"],\n",
    "    pairwise_analysis='off',\n",
    ")\n",
    "\n",
    "report.show_html('sweetviz_compare.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1388e",
   "metadata": {
    "papermill": {
     "duration": 0.002593,
     "end_time": "2025-01-24T17:43:23.457208",
     "exception": false,
     "start_time": "2025-01-24T17:43:23.454615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Data Preprocessing <a name=\"data-preprocessing\"></a>\n",
    "\n",
    "We preprocess the data by:\n",
    "1. Handling missing values\n",
    "2. Encoding categorical features\n",
    "3. Scaling numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242bba3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:43:23.463258Z",
     "iopub.status.busy": "2025-01-24T17:43:23.462975Z",
     "iopub.status.idle": "2025-01-24T17:43:28.861639Z",
     "shell.execute_reply": "2025-01-24T17:43:28.860890Z"
    },
    "papermill": {
     "duration": 5.403518,
     "end_time": "2025-01-24T17:43:28.863196",
     "exception": false,
     "start_time": "2025-01-24T17:43:23.459678",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Separate features and target variables\n",
    "X      = train.drop(['participant_id', 'ADHD_Outcome', 'Sex_F'], axis=1, errors='ignore')\n",
    "y_adhd = train['ADHD_Outcome']\n",
    "y_sex  = train['Sex_F']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "print(\"Preprocessing data...\")\n",
    "X_preprocessed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc9ccb",
   "metadata": {
    "papermill": {
     "duration": 0.002834,
     "end_time": "2025-01-24T17:43:28.869614",
     "exception": false,
     "start_time": "2025-01-24T17:43:28.866780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Model Training <a name=\"model-training\"></a>\n",
    "\n",
    "We use LightGBM, a gradient boosting framework, to train separate models for ADHD and sex prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc164f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:43:28.876283Z",
     "iopub.status.busy": "2025-01-24T17:43:28.875868Z",
     "iopub.status.idle": "2025-01-24T17:51:15.717648Z",
     "shell.execute_reply": "2025-01-24T17:51:15.716691Z"
    },
    "papermill": {
     "duration": 466.849101,
     "end_time": "2025-01-24T17:51:15.721591",
     "exception": false,
     "start_time": "2025-01-24T17:43:28.872490",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Split data into training and validation sets\n",
    "\n",
    "# Assign the split data to variables for better readability\n",
    "(\n",
    "    X_train, \n",
    "    X_val, \n",
    "    y_train_adhd, \n",
    "    y_val_adhd, \n",
    "    y_train_sex, \n",
    "    y_val_sex\n",
    ") = train_test_split(\n",
    "    X_preprocessed, \n",
    "    y_adhd, \n",
    "    y_sex, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y_adhd\n",
    ")\n",
    "\n",
    "# Calculate class weights for ADHD and sex\n",
    "adhd_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_adhd), y=y_adhd)\n",
    "sex_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_sex), y=y_sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53a8da",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# File paths for the saved models\n",
    "adhd_model_path = 'adhd_model.pkl'\n",
    "sex_model_path = 'sex_model.pkl'\n",
    "\n",
    "# Check if the ADHD model file exists\n",
    "if os.path.exists(adhd_model_path):\n",
    "    print(\"Loading ADHD model from file...\")\n",
    "    adhd_model = joblib.load(adhd_model_path)\n",
    "else:\n",
    "    # Define ADHD model\n",
    "    adhd_model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        num_leaves=63,\n",
    "        learning_rate=0.01,\n",
    "        n_estimators=1000,\n",
    "        scale_pos_weight=adhd_weights[1] / adhd_weights[0],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=-1\n",
    "    )\n",
    "    # Train ADHD model\n",
    "    print(\"Training ADHD model...\")\n",
    "    adhd_model.fit(X_train, y_train_adhd, eval_set=[(X_val, y_val_adhd)])\n",
    "    # Save ADHD model\n",
    "    joblib.dump(adhd_model, adhd_model_path)\n",
    "\n",
    "# Check if the Sex model file exists\n",
    "if os.path.exists(sex_model_path):\n",
    "    print(\"Loading Sex model from file...\")\n",
    "    sex_model = joblib.load(sex_model_path)\n",
    "else:\n",
    "    # Define Sex model\n",
    "    sex_model = lgb.LGBMClassifier(\n",
    "        objective='binary',\n",
    "        num_leaves=127,\n",
    "        learning_rate=0.005,\n",
    "        n_estimators=1000,\n",
    "        scale_pos_weight=sex_weights[1] / sex_weights[0],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=-1\n",
    "    )\n",
    "    # Train Sex model\n",
    "    print(\"Training Sex model...\")\n",
    "    sex_model.fit(X_train, y_train_sex, eval_set=[(X_val, y_val_sex)])\n",
    "    # Save Sex model\n",
    "    joblib.dump(sex_model, sex_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ece075",
   "metadata": {
    "papermill": {
     "duration": 0.002617,
     "end_time": "2025-01-24T17:51:15.727151",
     "exception": false,
     "start_time": "2025-01-24T17:51:15.724534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 5. Model Evaluation <a name=\"model-evaluation\"></a>\n",
    "\n",
    "We evaluate the models using the F1 score, which is the competition's evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e56fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:51:15.733928Z",
     "iopub.status.busy": "2025-01-24T17:51:15.733319Z",
     "iopub.status.idle": "2025-01-24T17:51:15.773796Z",
     "shell.execute_reply": "2025-01-24T17:51:15.772903Z"
    },
    "papermill": {
     "duration": 0.045199,
     "end_time": "2025-01-24T17:51:15.775125",
     "exception": false,
     "start_time": "2025-01-24T17:51:15.729926",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Make predictions on the validation set\n",
    "adhd_pred = adhd_model.predict(X_val)\n",
    "sex_pred = sex_model.predict(X_val)\n",
    "\n",
    "# Calculate F1 scores\n",
    "adhd_f1 = f1_score(y_val_adhd, adhd_pred)\n",
    "sex_f1 = f1_score(y_val_sex, sex_pred)\n",
    "combined_f1 = (adhd_f1 + sex_f1) / 2\n",
    "\n",
    "print(f\"ADHD F1 Score: {adhd_f1:.4f}\")\n",
    "print(f\"Sex F1 Score: {sex_f1:.4f}\")\n",
    "print(f\"Combined F1 Score: {combined_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb8813",
   "metadata": {
    "papermill": {
     "duration": 0.002743,
     "end_time": "2025-01-24T17:51:15.781124",
     "exception": false,
     "start_time": "2025-01-24T17:51:15.778381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Submission Generation <a name=\"submission-generation\"></a>\n",
    "\n",
    "We generate predictions for the test set and create a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ec76b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T17:51:15.787927Z",
     "iopub.status.busy": "2025-01-24T17:51:15.787672Z",
     "iopub.status.idle": "2025-01-24T17:51:16.261365Z",
     "shell.execute_reply": "2025-01-24T17:51:16.260517Z"
    },
    "papermill": {
     "duration": 0.478629,
     "end_time": "2025-01-24T17:51:16.262695",
     "exception": false,
     "start_time": "2025-01-24T17:51:15.784066",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "test_preprocessed = preprocessor.transform(test.drop('participant_id', axis=1, errors='ignore'))\n",
    "\n",
    "# Make predictions\n",
    "test_adhd_pred = adhd_model.predict(test_preprocessed)\n",
    "test_sex_pred = sex_model.predict(test_preprocessed)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.DataFrame({\n",
    "    'participant_id': test['participant_id'],\n",
    "    'ADHD_Outcome': test_adhd_pred,\n",
    "    'Sex_F': test_sex_pred\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcca79",
   "metadata": {
    "papermill": {
     "duration": 0.002892,
     "end_time": "2025-01-24T17:51:16.269646",
     "exception": false,
     "start_time": "2025-01-24T17:51:16.266754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 7. Conclusion <a name=\"conclusion\"></a>\n",
    "\n",
    "In this notebook, we:\n",
    "1. Loaded and preprocessed the WiDS Datathon 2025 dataset.\n",
    "2. Trained LightGBM models for ADHD and sex prediction.\n",
    "3. Evaluated the models using the F1 score.\n",
    "4. Generated a submission file for the competition.\n",
    "\n",
    "Further improvements could include:\n",
    "- Hyperparameter tuning\n",
    "- Feature engineering\n",
    "- Ensemble methods\n",
    "\n",
    "Good luck with the competition!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fcf1f8",
   "metadata": {},
   "source": [
    "# Sweetviz\n",
    "\n",
    "How can I appply this example to the data in this notebook:\n",
    "```python\n",
    "# import the necessary libraries\n",
    "import sweetviz as sv\n",
    "from sklearn.datasets import load_breast_cancer\n",
    " \n",
    "# Load the dataset\n",
    "cancer = load_breast_cancer(as_frame=True)\n",
    "# dataframe\n",
    "df = cancer.frame\n",
    " \n",
    "# Define the FeatureConfig object to force \n",
    "# the target feature to be numerical\n",
    "my_feature_config = sv.FeatureConfig(force_num=['target'])\n",
    " \n",
    "# Create a boolean array to use as the grouping condition\n",
    "condition_series = df['target'] == 0\n",
    " \n",
    "# Analyze the dataset with the specified FeatureConfig object \n",
    "# and grouping condition\n",
    "my_report = sv.compare_intra(df, \n",
    "                             condition_series, \n",
    "                             ['malignant', 'benign'], \n",
    "                             feat_cfg=my_feature_config, \n",
    "                             target_feat='target')\n",
    " \n",
    "# Generate and display the report\n",
    "my_report.show_html()\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39fa2cc",
   "metadata": {},
   "source": [
    "`my_feature_config` is an object used to configure how features are treated in the Sweetviz report. It allows you to specify certain features to be treated as numerical, categorical, or to be ignored. In the provided example, `my_feature_config` is used to force the target feature to be treated as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d39027",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m my_feature_config \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mFeatureConfig(force_num\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADHD_Outcome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex_F\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create a boolean array to use as the grouping condition\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m condition_series \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADHD_Outcome\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Analyze the dataset with the specified FeatureConfig object and grouping condition\u001b[39;00m\n\u001b[0;32m      9\u001b[0m my_report \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39mcompare_intra(\n\u001b[0;32m     10\u001b[0m     train, \n\u001b[0;32m     11\u001b[0m     condition_series, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     target_feat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADHD_Outcome\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "# Define the FeatureConfig object to force the target features to be numerical\n",
    "my_feature_config = sv.FeatureConfig(force_num=['ADHD_Outcome', 'Sex_F'])\n",
    "\n",
    "# Create a boolean array to use as the grouping condition\n",
    "condition_series = train['ADHD_Outcome'] == 1\n",
    "\n",
    "# Analyze the dataset with the specified FeatureConfig object and grouping condition\n",
    "my_report = sv.compare_intra(\n",
    "    train, \n",
    "    condition_series, \n",
    "    ['ADHD', 'No_ADHD'], \n",
    "    feat_cfg=my_feature_config, \n",
    "    target_feat='ADHD_Outcome'\n",
    ")\n",
    "\n",
    "# Generate and display the report\n",
    "my_report.show_html('compare_intra.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515bf873",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10712530,
     "sourceId": 90566,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "milliman_dublin_v005",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 497.545439,
   "end_time": "2025-01-24T17:51:17.393502",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-24T17:42:59.848063",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
